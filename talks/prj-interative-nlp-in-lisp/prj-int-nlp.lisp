;;; (c) 2017 Vsevolod Dyomkin <vseloved@gmail.com>

;;; This is example code used for presenting approaches to solving NLP problems
;;; Caution: it is dependent on my personal environment,
;;; so it won't work out-of-the-box!


(ql:quickload :yason)
(ql:quickload :cl-json)
(ql:quickload :wiki-lang-detect)


(defpackage :prj-int-nlp
  (:nicknames :prj)
  (:use :cl :rutilsx
        :nlp :ncore :nemb :nlearn :nutil))

(in-package :prj)
(named-readtables:in-readtable rutilsx-readtable)


;;; View a single file's contents

(gzip-stream:with-open-gzip-file (in "lang-uk/1551.gov.ua/raw/А/А-10008.json.gz")
  (let ((in (flex:make-flexi-stream in :external-format :utf-8)))
    (yason:parse in)))


;;; Gather raw data

(let (raw)
  (dolist (file (directory "lang-uk/1551.gov.ua/raw/*/*.gz"))
    (progress-bar)
    (gzip-stream:with-open-gzip-file (in file)
      (let ((in (flex:make-flexi-stream in :external-format :utf-8)))
        (with ((json (first (yason:parse in))))
          (push (pair (? json "CallZText")
                      (intern (? json "CallZType") :keyword))
                raw))))
  (defpar *raw* raw)))


;;; Analyze categories

(let ((cats #{}))
  (dolist (item *raw*)
    (:+ (get# (rt item) cats 0)))
  (defpar *cats* cats))

(defpar *top-cats*
    (-> (ht->pairs *cats*)
        (remove-if ^(< (rt %) 100) %)
        (sort  '> :key 'rt)))

(map nil ^(format t "~(~A~) ~A~%" (lt %) (rt %))
     *top-cats*)


;;; Averaged perceptron learner

(defclass agent-1551 (avg-perceptron)
  ())


;;; Feature extraction

(defun list-ngrams (text)
  (let (prev
        rez)
    (dolist (sent (flatten (tokenize *full-text-tokenizer* text) 1))
      (dolist (tok sent)
        (let ((word (string-downcase @tok.word)))
          (if (some 'alphanumericp word)
              (progn
                (push word rez)
                (when prev
                  (push (fmt "~A ~A" prev word) rez))
                (:= prev word))
              (void prev)))))
    rez))

(defmethod extract-fs ((model agent-1551) &rest args)
  (list-ngrams (first args)))

(defpar *fs* nil)
(defpar *ngrams* #{equalp})

(let ((agent (make 'agent-1551)))
  (dolist (raw *raw*)
    (let ((fs (extract-fs agent (? raw 0))))
      (push (pair fs (? raw 1))
            *fs*)
      (dolist (ngram fs)
        (:+ (get# ngram *ngrams* 0))))))


;;; Discriminate by lang

(let (uk ru ot (cc 0))
  (dolist (item *raw*)
    (when (zerop (rem (:+ cc) 100)) (princ "."))
    (unless (blankp (lt item))
      (case (wild:text-lang (lt item))
        (:uk (push item uk))
        (:ru (push item ru))
        (otherwise (push item ot)))))
  (defpar *uk* uk)
  (defpar *ru* ru)
  (defpar *ot* ot))


;;; Preparation of the training/test sets

(defun split-train-test (data &optional (split 0.7))
  (with ((split-point (floor (* (length data) split)))
         (agent (make 'agent-1551))
         (data (mapcar ^(make-sample :fs (extract-fs agent (lt %))
                                     :gold (rt %))
                       data)))
    (values (subseq data 0 split-point)
            (subseq data split-point))))

(with ((train test (split-train-test *fs*)))
  (defpar *train* train)
  (defpar *test* test))

(with ((train test (split-train-test *uk*)))
  (defpar *train-uk* train)
  (defpar *test-uk* test))


;;; Training logs

;; PRJ> (defpar *agent*
;;          (train (make 'agent-1551)
;;                 (mapcar *train*
;;                         :verbose t)))

;; ==== Epoch: 1 ====

;; 144 / 893 = 16.13% - 1.% 
;; 363 / 1785 = 20.34% - 2.% 
;; 684 / 2677 = 25.55% - 3.% 
;; 999 / 3569 = 27.99% - 4.% 
;; 1252 / 4461 = 28.07% - 5.% 
;; 1491 / 5353 = 27.85% - 6.% 
;; 1776 / 6245 = 28.44% - 7.% 
;; 2035 / 7137 = 28.51% - 8.% 
;; 2332 / 8029 = 29.04% - 9.% 
;; 2616 / 8921 = 29.32% - 10.% 
;; 2891 / 9813 = 29.46% - 11.% 
;; 3170 / 10705 = 29.61% - 12.% 
;; 3497 / 11597 = 30.15% - 13.% 
;; 3819 / 12489 = 30.58% - 14.% 
;; 4115 / 13381 = 30.75% - 15.% 
;; 4465 / 14273 = 31.28% - 16.% 
;; 4791 / 15165 = 31.59% - 17.% 
;; 5154 / 16057 =  32.1% - 18.% 
;; 5459 / 16949 = 32.21% - 19.% 
;; 5788 / 17841 = 32.44% - 20.% 
;; 6152 / 18733 = 32.84% - 21.% 
;; 6490 / 19625 = 33.07% - 22.% 
;; 6824 / 20517 = 33.26% - 23.% 
;; 7204 / 21409 = 33.65% - 24.% 
;; 7535 / 22301 = 33.79% - 25.% 
;; 7848 / 23193 = 33.84% - 26.% 
;; 8220 / 24085 = 34.13% - 27.% 
;; 8579 / 24977 = 34.35% - 28.% 
;; 8917 / 25869 = 34.47% - 29.% 
;; 9311 / 26761 = 34.79% - 30.% 
;; 9684 / 27653 = 35.02% - 31.% 
;; 10027 / 28545 = 35.13% - 32.% 
;; 10375 / 29437 = 35.24% - 33.% 
;; 10744 / 30329 = 35.42% - 34.% 
;; 11128 / 31221 = 35.64% - 35.% 
;; 11500 / 32113 = 35.81% - 36.% 
;; 11847 / 33005 = 35.89% - 37.% 
;; 12214 / 33897 = 36.03% - 38.% 
;; 12572 / 34789 = 36.14% - 39.% 
;; 12923 / 35681 = 36.22% - 40.% 
;; 13293 / 36573 = 36.35% - 41.% 
;; 13668 / 37465 = 36.48% - 42.% 
;; 14037 / 38357 =  36.6% - 43.% 
;; 14438 / 39249 = 36.79% - 44.% 
;; 14862 / 40141 = 37.02% - 45.% 
;; 15283 / 41033 = 37.25% - 46.% 
;; 15701 / 41925 = 37.45% - 47.% 
;; 16106 / 42817 = 37.62% - 48.% 
;; 16531 / 43709 = 37.82% - 49.% 
;; 16951 / 44601 = 38.01% - 50.% 
;; 17417 / 45493 = 38.29% - 51.% 
;; 17811 / 46385 =  38.4% - 52.% 
;; 18204 / 47277 =  38.5% - 53.% 
;; 18624 / 48169 = 38.66% - 54.% 
;; 19029 / 49061 = 38.79% - 55.% 
;; 19408 / 49953 = 38.85% - 56.% 
;; 19810 / 50845 = 38.96% - 57.% 
;; 20249 / 51737 = 39.14% - 58.% 
;; 20650 / 52629 = 39.24% - 59.% 
;; 21080 / 53521 = 39.39% - 60.% 
;; 21499 / 54413 = 39.51% - 61.% 
;; 21915 / 55305 = 39.63% - 62.% 
;; 22368 / 56197 =  39.8% - 63.% 
;; 22793 / 57089 = 39.93% - 64.% 
;; 23209 / 57981 = 40.03% - 65.% 
;; 23603 / 58873 = 40.09% - 66.% 
;; 23987 / 59765 = 40.14% - 67.% 
;; 24399 / 60657 = 40.22% - 68.% 
;; 24852 / 61549 = 40.38% - 69.% 
;; 25251 / 62441 = 40.44% - 70.% 
;; 25651 / 63333 =  40.5% - 71.% 
;; 26043 / 64225 = 40.55% - 72.% 
;; 26469 / 65117 = 40.65% - 73.% 
;; 26865 / 66009 =  40.7% - 74.% 
;; 27283 / 66901 = 40.78% - 75.% 
;; 27673 / 67793 = 40.82% - 76.% 
;; 28069 / 68685 = 40.87% - 77.% 
;; 28452 / 69577 = 40.89% - 78.% 
;; 28887 / 70469 = 40.99% - 79.% 
;; 29296 / 71361 = 41.05% - 80.% 
;; 29662 / 72253 = 41.05% - 81.% 
;; 30079 / 73145 = 41.12% - 82.% 
;; 30504 / 74037 =  41.2% - 83.% 
;; 30929 / 74929 = 41.28% - 84.% 
;; 31284 / 75821 = 41.26% - 85.% 
;; 31661 / 76713 = 41.27% - 86.% 
;; 32083 / 77605 = 41.34% - 87.% 
;; 32517 / 78497 = 41.42% - 88.% 
;; 32950 / 79389 =  41.5% - 89.% 
;; 33341 / 80281 = 41.53% - 90.% 
;; 33704 / 81173 = 41.52% - 91.% 
;; 34111 / 82065 = 41.57% - 92.% 
;; 34515 / 82957 = 41.61% - 93.% 
;; 34883 / 83849 =  41.6% - 94.% 
;; 35321 / 84741 = 41.68% - 95.% 
;; 35725 / 85633 = 41.72% - 96.% 
;; 36183 / 86525 = 41.82% - 97.% 
;; 36642 / 87417 = 41.92% - 98.% 
;; 37066 / 88309 = 41.97% - 99.% 


;; ==== Epoch: 2 ====

;; 695 / 893 = 77.83% - 1.% 
;; 1400 / 1785 = 78.43% - 2.% 
;; 2122 / 2677 = 79.27% - 3.% 
;; 2851 / 3569 = 79.88% - 4.% 
;; 3560 / 4461 =  79.8% - 5.% 
;; 4277 / 5353 =  79.9% - 6.% 
;; 4972 / 6245 = 79.62% - 7.% 
;; 5688 / 7137 =  79.7% - 8.% 
;; 6388 / 8029 = 79.56% - 9.% 
;; 7108 / 8921 = 79.68% - 10.% 
;; 7816 / 9813 = 79.65% - 11.% 
;; 8524 / 10705 = 79.63% - 12.% 
;; 9249 / 11597 = 79.75% - 13.% 
;; 9966 / 12489 =  79.8% - 14.% 
;; 10678 / 13381 =  79.8% - 15.% 
;; 11348 / 14273 = 79.51% - 16.% 
;; 12049 / 15165 = 79.45% - 17.% 
;; 12761 / 16057 = 79.47% - 18.% 
;; 13483 / 16949 = 79.55% - 19.% 
;; 14165 / 17841 =  79.4% - 20.% 
;; 14880 / 18733 = 79.43% - 21.% 
;; 15586 / 19625 = 79.42% - 22.% 
;; 16289 / 20517 = 79.39% - 23.% 
;; 17005 / 21409 = 79.43% - 24.% 
;; 17724 / 22301 = 79.48% - 25.% 
;; 18428 / 23193 = 79.46% - 26.% 
;; 19131 / 24085 = 79.43% - 27.% 
;; 19824 / 24977 = 79.37% - 28.% 
;; 20535 / 25869 = 79.38% - 29.% 
;; 21262 / 26761 = 79.45% - 30.% 
;; 21988 / 27653 = 79.51% - 31.% 
;; 22709 / 28545 = 79.56% - 32.% 
;; 23410 / 29437 = 79.53% - 33.% 
;; 24138 / 30329 = 79.59% - 34.% 
;; 24831 / 31221 = 79.53% - 35.% 
;; 25536 / 32113 = 79.52% - 36.% 
;; 26269 / 33005 = 79.59% - 37.% 
;; 26974 / 33897 = 79.58% - 38.% 
;; 27688 / 34789 = 79.59% - 39.% 
;; 28390 / 35681 = 79.57% - 40.% 
;; 29083 / 36573 = 79.52% - 41.% 
;; 29782 / 37465 = 79.49% - 42.% 
;; 30471 / 38357 = 79.44% - 43.% 
;; 31179 / 39249 = 79.44% - 44.% 
;; 31882 / 40141 = 79.43% - 45.% 
;; 32584 / 41033 = 79.41% - 46.% 
;; 33274 / 41925 = 79.37% - 47.% 
;; 33992 / 42817 = 79.39% - 48.% 
;; 34690 / 43709 = 79.37% - 49.% 
;; 35405 / 44601 = 79.38% - 50.% 
;; 36121 / 45493 =  79.4% - 51.% 
;; 36826 / 46385 = 79.39% - 52.% 
;; 37544 / 47277 = 79.41% - 53.% 
;; 38241 / 48169 = 79.39% - 54.% 
;; 38959 / 49061 = 79.41% - 55.% 
;; 39666 / 49953 = 79.41% - 56.% 
;; 40363 / 50845 = 79.38% - 57.% 
;; 41087 / 51737 = 79.42% - 58.% 
;; 41788 / 52629 =  79.4% - 59.% 
;; 42501 / 53521 = 79.41% - 60.% 
;; 43190 / 54413 = 79.37% - 61.% 
;; 43903 / 55305 = 79.38% - 62.% 
;; 44590 / 56197 = 79.35% - 63.% 
;; 45265 / 57089 = 79.29% - 64.% 
;; 45978 / 57981 =  79.3% - 65.% 
;; 46668 / 58873 = 79.27% - 66.% 
;; 47377 / 59765 = 79.27% - 67.% 
;; 48065 / 60657 = 79.24% - 68.% 
;; 48778 / 61549 = 79.25% - 69.% 
;; 49511 / 62441 = 79.29% - 70.% 
;; 50207 / 63333 = 79.27% - 71.% 
;; 50910 / 64225 = 79.27% - 72.% 
;; 51623 / 65117 = 79.28% - 73.% 
;; 52302 / 66009 = 79.23% - 74.% 
;; 53004 / 66901 = 79.23% - 75.% 
;; 53697 / 67793 = 79.21% - 76.% 
;; 54396 / 68685 =  79.2% - 77.% 
;; 55105 / 69577 =  79.2% - 78.% 
;; 55814 / 70469 =  79.2% - 79.% 
;; 56529 / 71361 = 79.22% - 80.% 
;; 57223 / 72253 =  79.2% - 81.% 
;; 57926 / 73145 = 79.19% - 82.% 
;; 58618 / 74037 = 79.17% - 83.% 
;; 59345 / 74929 =  79.2% - 84.% 
;; 60050 / 75821 =  79.2% - 85.% 
;; 60744 / 76713 = 79.18% - 86.% 
;; 61446 / 77605 = 79.18% - 87.% 
;; 62153 / 78497 = 79.18% - 88.% 
;; 62830 / 79389 = 79.14% - 89.% 
;; 63531 / 80281 = 79.14% - 90.% 
;; 64219 / 81173 = 79.11% - 91.% 
;; 64936 / 82065 = 79.13% - 92.% 
;; 65643 / 82957 = 79.13% - 93.% 
;; 66343 / 83849 = 79.12% - 94.% 
;; 67033 / 84741 =  79.1% - 95.% 
;; 67723 / 85633 = 79.09% - 96.% 
;; 68418 / 86525 = 79.07% - 97.% 
;; 69154 / 87417 = 79.11% - 98.% 
;; 69854 / 88309 =  79.1% - 99.% 


;; ==== Epoch: 3 ====

;; 788 / 893 = 88.24% - 1.% 
;; 1567 / 1785 = 87.79% - 2.% 
;; 2356 / 2677 = 88.01% - 3.% 
;; 3149 / 3569 = 88.23% - 4.% 
;; 3946 / 4461 = 88.46% - 5.% 
;; 4728 / 5353 = 88.32% - 6.% 
;; 5531 / 6245 = 88.57% - 7.% 
;; 6334 / 7137 = 88.75% - 8.% 
;; 7110 / 8029 = 88.55% - 9.% 
;; 7910 / 8921 = 88.67% - 10.% 
;; 8684 / 9813 = 88.49% - 11.% 
;; 9472 / 10705 = 88.48% - 12.% 
;; 10245 / 11597 = 88.34% - 13.% 
;; 11042 / 12489 = 88.41% - 14.% 
;; 11840 / 13381 = 88.48% - 15.% 
;; 12641 / 14273 = 88.57% - 16.% 
;; 13456 / 15165 = 88.73% - 17.% 
;; 14257 / 16057 = 88.79% - 18.% 
;; 15062 / 16949 = 88.87% - 19.% 
;; 15867 / 17841 = 88.94% - 20.% 
;; 16657 / 18733 = 88.92% - 21.% 
;; 17459 / 19625 = 88.96% - 22.% 
;; 18260 / 20517 =  89.0% - 23.% 
;; 19043 / 21409 = 88.95% - 24.% 
;; 19840 / 22301 = 88.96% - 25.% 
;; 20635 / 23193 = 88.97% - 26.% 
;; 21425 / 24085 = 88.96% - 27.% 
;; 22207 / 24977 = 88.91% - 28.% 
;; 22998 / 25869 =  88.9% - 29.% 
;; 23795 / 26761 = 88.92% - 30.% 
;; 24596 / 27653 = 88.95% - 31.% 
;; 25375 / 28545 = 88.89% - 32.% 
;; 26169 / 29437 =  88.9% - 33.% 
;; 26957 / 30329 = 88.88% - 34.% 
;; 27736 / 31221 = 88.84% - 35.% 
;; 28517 / 32113 =  88.8% - 36.% 
;; 29312 / 33005 = 88.81% - 37.% 
;; 30088 / 33897 = 88.76% - 38.% 
;; 30882 / 34789 = 88.77% - 39.% 
;; 31659 / 35681 = 88.73% - 40.% 
;; 32456 / 36573 = 88.74% - 41.% 
;; 33249 / 37465 = 88.75% - 42.% 
;; 34045 / 38357 = 88.76% - 43.% 
;; 34839 / 39249 = 88.76% - 44.% 
;; 35620 / 40141 = 88.74% - 45.% 
;; 36418 / 41033 = 88.75% - 46.% 
;; 37201 / 41925 = 88.73% - 47.% 
;; 37973 / 42817 = 88.69% - 48.% 
;; 38765 / 43709 = 88.69% - 49.% 
;; 39555 / 44601 = 88.69% - 50.% 
;; 40344 / 45493 = 88.68% - 51.% 
;; 41133 / 46385 = 88.68% - 52.% 
;; 41916 / 47277 = 88.66% - 53.% 
;; 42692 / 48169 = 88.63% - 54.% 
;; 43494 / 49061 = 88.65% - 55.% 
;; 44266 / 49953 = 88.62% - 56.% 
;; 45037 / 50845 = 88.58% - 57.% 
;; 45817 / 51737 = 88.56% - 58.% 
;; 46624 / 52629 = 88.59% - 59.% 
;; 47417 / 53521 =  88.6% - 60.% 
;; 48192 / 54413 = 88.57% - 61.% 
;; 48969 / 55305 = 88.54% - 62.% 
;; 49755 / 56197 = 88.54% - 63.% 
;; 50543 / 57089 = 88.53% - 64.% 
;; 51338 / 57981 = 88.54% - 65.% 
;; 52109 / 58873 = 88.51% - 66.% 
;; 52881 / 59765 = 88.48% - 67.% 
;; 53663 / 60657 = 88.47% - 68.% 
;; 54434 / 61549 = 88.44% - 69.% 
;; 55197 / 62441 =  88.4% - 70.% 
;; 55979 / 63333 = 88.39% - 71.% 
;; 56762 / 64225 = 88.38% - 72.% 
;; 57580 / 65117 = 88.43% - 73.% 
;; 58361 / 66009 = 88.41% - 74.% 
;; 59138 / 66901 =  88.4% - 75.% 
;; 59905 / 67793 = 88.36% - 76.% 
;; 60690 / 68685 = 88.36% - 77.% 
;; 61455 / 69577 = 88.33% - 78.% 
;; 62236 / 70469 = 88.32% - 79.% 
;; 63013 / 71361 =  88.3% - 80.% 
;; 63790 / 72253 = 88.29% - 81.% 
;; 64569 / 73145 = 88.28% - 82.% 
;; 65341 / 74037 = 88.25% - 83.% 
;; 66121 / 74929 = 88.24% - 84.% 
;; 66898 / 75821 = 88.23% - 85.% 
;; 67658 / 76713 =  88.2% - 86.% 
;; 68440 / 77605 = 88.19% - 87.% 
;; 69224 / 78497 = 88.19% - 88.% 
;; 70012 / 79389 = 88.19% - 89.% 
;; 70807 / 80281 =  88.2% - 90.% 
;; 71578 / 81173 = 88.18% - 91.% 
;; 72349 / 82065 = 88.16% - 92.% 
;; 73125 / 82957 = 88.15% - 93.% 
;; 73907 / 83849 = 88.14% - 94.% 
;; 74666 / 84741 = 88.11% - 95.% 
;; 75443 / 85633 =  88.1% - 96.% 
;; 76216 / 86525 = 88.09% - 97.% 
;; 76972 / 87417 = 88.05% - 98.% 
;; 77761 / 88309 = 88.06% - 99.% 


;; ==== Epoch: 4 ====

;; 834 / 893 = 93.39% - 1.% 
;; 1667 / 1785 = 93.39% - 2.% 
;; 2492 / 2677 = 93.09% - 3.% 
;; 3310 / 3569 = 92.74% - 4.% 
;; 4131 / 4461 =  92.6% - 5.% 
;; 4956 / 5353 = 92.58% - 6.% 
;; 5765 / 6245 = 92.31% - 7.% 
;; 6593 / 7137 = 92.38% - 8.% 
;; 7415 / 8029 = 92.35% - 9.% 
;; 8254 / 8921 = 92.52% - 10.% 
;; 9081 / 9813 = 92.54% - 11.% 
;; 9903 / 10705 = 92.51% - 12.% 
;; 10737 / 11597 = 92.58% - 13.% 
;; 11578 / 12489 = 92.71% - 14.% 
;; 12401 / 13381 = 92.68% - 15.% 
;; 13223 / 14273 = 92.64% - 16.% 
;; 14044 / 15165 = 92.61% - 17.% 
;; 14876 / 16057 = 92.64% - 18.% 
;; 15691 / 16949 = 92.58% - 19.% 
;; 16502 / 17841 = 92.49% - 20.% 
;; 17335 / 18733 = 92.54% - 21.% 
;; 18165 / 19625 = 92.56% - 22.% 
;; 18992 / 20517 = 92.57% - 23.% 
;; 19811 / 21409 = 92.54% - 24.% 
;; 20645 / 22301 = 92.57% - 25.% 
;; 21470 / 23193 = 92.57% - 26.% 
;; 22293 / 24085 = 92.56% - 27.% 
;; 23125 / 24977 = 92.59% - 28.% 
;; 23961 / 25869 = 92.62% - 29.% 
;; 24795 / 26761 = 92.65% - 30.% 
;; 25621 / 27653 = 92.65% - 31.% 
;; 26455 / 28545 = 92.68% - 32.% 
;; 27290 / 29437 = 92.71% - 33.% 
;; 28117 / 30329 = 92.71% - 34.% 
;; 28943 / 31221 =  92.7% - 35.% 
;; 29772 / 32113 = 92.71% - 36.% 
;; 30604 / 33005 = 92.73% - 37.% 
;; 31429 / 33897 = 92.72% - 38.% 
;; 32262 / 34789 = 92.74% - 39.% 
;; 33082 / 35681 = 92.72% - 40.% 
;; 33918 / 36573 = 92.74% - 41.% 
;; 34744 / 37465 = 92.74% - 42.% 
;; 35563 / 38357 = 92.72% - 43.% 
;; 36387 / 39249 = 92.71% - 44.% 
;; 37209 / 40141 =  92.7% - 45.% 
;; 38027 / 41033 = 92.67% - 46.% 
;; 38833 / 41925 = 92.62% - 47.% 
;; 39665 / 42817 = 92.64% - 48.% 
;; 40477 / 43709 = 92.61% - 49.% 
;; 41298 / 44601 = 92.59% - 50.% 
;; 42135 / 45493 = 92.62% - 51.% 
;; 42949 / 46385 = 92.59% - 52.% 
;; 43774 / 47277 = 92.59% - 53.% 
;; 44611 / 48169 = 92.61% - 54.% 
;; 45439 / 49061 = 92.62% - 55.% 
;; 46239 / 49953 = 92.57% - 56.% 
;; 47056 / 50845 = 92.55% - 57.% 
;; 47864 / 51737 = 92.51% - 58.% 
;; 48663 / 52629 = 92.46% - 59.% 
;; 49466 / 53521 = 92.42% - 60.% 
;; 50282 / 54413 = 92.41% - 61.% 
;; 51105 / 55305 = 92.41% - 62.% 
;; 51921 / 56197 = 92.39% - 63.% 
;; 52734 / 57089 = 92.37% - 64.% 
;; 53542 / 57981 = 92.34% - 65.% 
;; 54371 / 58873 = 92.35% - 66.% 
;; 55195 / 59765 = 92.35% - 67.% 
;; 56006 / 60657 = 92.33% - 68.% 
;; 56827 / 61549 = 92.33% - 69.% 
;; 57654 / 62441 = 92.33% - 70.% 
;; 58473 / 63333 = 92.33% - 71.% 
;; 59278 / 64225 =  92.3% - 72.% 
;; 60094 / 65117 = 92.29% - 73.% 
;; 60893 / 66009 = 92.25% - 74.% 
;; 61704 / 66901 = 92.23% - 75.% 
;; 62528 / 67793 = 92.23% - 76.% 
;; 63347 / 68685 = 92.23% - 77.% 
;; 64161 / 69577 = 92.22% - 78.% 
;; 64970 / 70469 =  92.2% - 79.% 
;; 65790 / 71361 = 92.19% - 80.% 
;; 66604 / 72253 = 92.18% - 81.% 
;; 67435 / 73145 = 92.19% - 82.% 
;; 68249 / 74037 = 92.18% - 83.% 
;; 69058 / 74929 = 92.16% - 84.% 
;; 69853 / 75821 = 92.13% - 85.% 
;; 70666 / 76713 = 92.12% - 86.% 
;; 71486 / 77605 = 92.12% - 87.% 
;; 72311 / 78497 = 92.12% - 88.% 
;; 73138 / 79389 = 92.13% - 89.% 
;; 73949 / 80281 = 92.11% - 90.% 
;; 74759 / 81173 =  92.1% - 91.% 
;; 75566 / 82065 = 92.08% - 92.% 
;; 76372 / 82957 = 92.06% - 93.% 
;; 77187 / 83849 = 92.05% - 94.% 
;; 78003 / 84741 = 92.05% - 95.% 
;; 78813 / 85633 = 92.04% - 96.% 
;; 79618 / 86525 = 92.02% - 97.% 
;; 80441 / 87417 = 92.02% - 98.% 
;; 81254 / 88309 = 92.01% - 99.% 


;; ==== Epoch: 5 ====

;; 838 / 893 = 93.84% - 1.% 
;; 1677 / 1785 = 93.95% - 2.% 
;; 2520 / 2677 = 94.14% - 3.% 
;; 3375 / 3569 = 94.56% - 4.% 
;; 4225 / 4461 = 94.71% - 5.% 
;; 5088 / 5353 = 95.05% - 6.% 
;; 5937 / 6245 = 95.07% - 7.% 
;; 6787 / 7137 =  95.1% - 8.% 
;; 7630 / 8029 = 95.03% - 9.% 
;; 8473 / 8921 = 94.98% - 10.% 
;; 9315 / 9813 = 94.93% - 11.% 
;; 10149 / 10705 = 94.81% - 12.% 
;; 10988 / 11597 = 94.75% - 13.% 
;; 11830 / 12489 = 94.72% - 14.% 
;; 12666 / 13381 = 94.66% - 15.% 
;; 13510 / 14273 = 94.65% - 16.% 
;; 14351 / 15165 = 94.63% - 17.% 
;; 15179 / 16057 = 94.53% - 18.% 
;; 16026 / 16949 = 94.55% - 19.% 
;; 16867 / 17841 = 94.54% - 20.% 
;; 17706 / 18733 = 94.52% - 21.% 
;; 18548 / 19625 = 94.51% - 22.% 
;; 19394 / 20517 = 94.53% - 23.% 
;; 20236 / 21409 = 94.52% - 24.% 
;; 21082 / 22301 = 94.53% - 25.% 
;; 21924 / 23193 = 94.53% - 26.% 
;; 22761 / 24085 =  94.5% - 27.% 
;; 23606 / 24977 = 94.51% - 28.% 
;; 24447 / 25869 =  94.5% - 29.% 
;; 25291 / 26761 = 94.51% - 30.% 
;; 26114 / 27653 = 94.43% - 31.% 
;; 26967 / 28545 = 94.47% - 32.% 
;; 27808 / 29437 = 94.47% - 33.% 
;; 28654 / 30329 = 94.48% - 34.% 
;; 29486 / 31221 = 94.44% - 35.% 
;; 30322 / 32113 = 94.42% - 36.% 
;; 31163 / 33005 = 94.42% - 37.% 
;; 32003 / 33897 = 94.41% - 38.% 
;; 32835 / 34789 = 94.38% - 39.% 
;; 33669 / 35681 = 94.36% - 40.% 
;; 34503 / 36573 = 94.34% - 41.% 
;; 35341 / 37465 = 94.33% - 42.% 
;; 36190 / 38357 = 94.35% - 43.% 
;; 37024 / 39249 = 94.33% - 44.% 
;; 37865 / 40141 = 94.33% - 45.% 
;; 38704 / 41033 = 94.32% - 46.% 
;; 39544 / 41925 = 94.32% - 47.% 
;; 40379 / 42817 = 94.31% - 48.% 
;; 41212 / 43709 = 94.29% - 49.% 
;; 42056 / 44601 = 94.29% - 50.% 
;; 42898 / 45493 =  94.3% - 51.% 
;; 43737 / 46385 = 94.29% - 52.% 
;; 44569 / 47277 = 94.27% - 53.% 
;; 45414 / 48169 = 94.28% - 54.% 
;; 46255 / 49061 = 94.28% - 55.% 
;; 47100 / 49953 = 94.29% - 56.% 
;; 47922 / 50845 = 94.25% - 57.% 
;; 48766 / 51737 = 94.26% - 58.% 
;; 49598 / 52629 = 94.24% - 59.% 
;; 50438 / 53521 = 94.24% - 60.% 
;; 51273 / 54413 = 94.23% - 61.% 
;; 52113 / 55305 = 94.23% - 62.% 
;; 52943 / 56197 = 94.21% - 63.% 
;; 53789 / 57089 = 94.22% - 64.% 
;; 54636 / 57981 = 94.23% - 65.% 
;; 55478 / 58873 = 94.23% - 66.% 
;; 56325 / 59765 = 94.24% - 67.% 
;; 57156 / 60657 = 94.23% - 68.% 
;; 57988 / 61549 = 94.21% - 69.% 
;; 58829 / 62441 = 94.22% - 70.% 
;; 59659 / 63333 =  94.2% - 71.% 
;; 60498 / 64225 =  94.2% - 72.% 
;; 61338 / 65117 =  94.2% - 73.% 
;; 62191 / 66009 = 94.22% - 74.% 
;; 63034 / 66901 = 94.22% - 75.% 
;; 63876 / 67793 = 94.22% - 76.% 
;; 64722 / 68685 = 94.23% - 77.% 
;; 65561 / 69577 = 94.23% - 78.% 
;; 66383 / 70469 =  94.2% - 79.% 
;; 67223 / 71361 =  94.2% - 80.% 
;; 68061 / 72253 =  94.2% - 81.% 
;; 68903 / 73145 =  94.2% - 82.% 
;; 69735 / 74037 = 94.19% - 83.% 
;; 70561 / 74929 = 94.17% - 84.% 
;; 71392 / 75821 = 94.16% - 85.% 
;; 72220 / 76713 = 94.14% - 86.% 
;; 73066 / 77605 = 94.15% - 87.% 
;; 73906 / 78497 = 94.15% - 88.% 
;; 74736 / 79389 = 94.14% - 89.% 
;; 75571 / 80281 = 94.13% - 90.% 
;; 76399 / 81173 = 94.12% - 91.% 
;; 77238 / 82065 = 94.12% - 92.% 
;; 78061 / 82957 =  94.1% - 93.% 
;; 78899 / 83849 =  94.1% - 94.% 
;; 79740 / 84741 =  94.1% - 95.% 
;; 80561 / 85633 = 94.08% - 96.% 
;; 81402 / 86525 = 94.08% - 97.% 
;; 82225 / 87417 = 94.06% - 98.% 
;; 83047 / 88309 = 94.04% - 99.% 
;; #<AGENT-1551 {104A4A4AE3}>

;; PRJ> (accuracy *agent* (mapcar ^(make-sample :fs (lt %) :gold (rt %))
;;                                *test*))
;; ....................................................................................................
;; 62.33933


;; PRJ> (accuracy *agent-uk* *test-uk*)
;; ................................................................................................
;; 62.49218


;;; Vectors

;; file obtained from here: http://lang.org.ua/static/downloads/models/ubercorpus.cased.tokenized.glove.300d.bz2

(defpar *glove-uk* (make 'nemb:lazy-mem-vecs :order 300))
(nemb::init-vecs *glove-uk* "glove.txt")  


;;; Utilities to work with vectors

(defun avg (&rest numbers)
  (/ (reduce '+ numbers)
     (length numbers)))

(defun avg-vecs (vecs)
  (apply 'map* 'avg
         (coerce (remove-if ^(every 'zerop %)
                            vecs)
                 'list)))

(defun 2vecs (str)
  (mapcar ^(2vec *glove-uk* %)
          (split #\Space str)))

(let ((cat-vecs #{}))
  (dolist (cat-freq *top-cats*)
    (let ((cat (lt cat-freq)))
      (:= (? cat-vecs cat)
          (avg-vecs (2vecs (symbol-name cat))))))
  (defpar *cat-vecs* cat-vecs))

(defun l2-dist (vec1 vec2)
  (sqrt (sum ^(expt (- % %%) 2)
             vec1 vec2)))


;;; Training data for RNN

(defpar *rnn-train-uk*
    (mapcar ^(make-sample
              :fs (map 'vector ^(2vec *glove-uk* %)
                       (remove-if ^(find #\Space %)
                                  @%.fs))
              :gold @%.gold)
            *train-uk*))


;;; RNN (LSTM) training

(defclass fnn-1552 (mgl:fnn)
  ())
    
(defun make-rnn-1552 ()
  (mgl:build-rnn ()
    (mgl:build-fnn (:class 'fnn-1552)
      (input (mgl:->input :size 300))
      (h (mgl:->lstm input :name 'h :size 1))
      (prediction (mgl:->softmax-xe-loss
                   (mgl:->activation h :name 'prediction
                                       :size (length *top-cats*)))))))

(defmethod mgl:set-input (instances (fnn fnn-1552))
  (let ((input-nodes (mgl:nodes (mgl:find-clump 'input fnn))))
    (:= (mgl:target (mgl:find-clump 'prediction fnn))
        (loop :for stripe :upfrom 0
              :for instance :in instances
              :do (dotimes (i 300)
                    (:= (mgl:mref input-nodes stripe i)
                        (? instance 0 i)))
              :collect (position (? instance 1) *top-cats*)))))

(defun make-sampler (data)
  (mapcar ^(mgl:make-sequence-sampler
            (mapcar 'pair (coerce @%.fs 'list)
                    (list @%.gold)))
          data))

(defun log-test-error (optimizer learner)
  (when (zerop (mgl:n-instances optimizer))
    (describe optimizer)
    (describe (mgl:bpn learner)))
  (let ((rnn (mgl:bpn learner)))
    (mgl:log-padded
     (mgl:monitor-bpn-results
      (make-sampler (take 100 (shuffle *rnn-train-uk*)))
      rnn
      (mgl:make-cost-monitors
       rnn :attributes '(:event "pred.")))))
  (mgl:log-mat-room))
 
(defun train-rnn-1552 ()
  (let ((rnn (make-rnn-1552)))
    (:= (mgl:max-n-stripes rnn) 50)
    (mgl:map-segments (lambda (weights)
                        (with ((fan-in (mgl:mat-dimension (mgl:nodes weights) 0))
                               (limit (sqrt (/ 6 fan-in))))
                          (mgl:uniform-random! (mgl:nodes weights)
                                               :limit (* 2 limit))
                          (mgl:.+! (- limit) (mgl:nodes weights))))
                      rnn)
    (mgl:minimize (mgl:monitor-optimization-periodically
                   (make 'mgl:adam-optimizer
                         :learning-rate 0.2
                         :mean-decay 0.9
                         :mean-decay-decay 0.9
                         :variance-decay 0.9
                         :batch-size 100)
                   '((:fn log-test-error :period 30000)
                     (:fn mgl:reset-optimization-monitors :period 3000)))
                  (make 'mgl:bp-learner
                        :bpn rnn
                        :monitors (mgl:make-cost-monitors rnn))
                  :dataset (make-sampler *rnn-train-uk*))))
